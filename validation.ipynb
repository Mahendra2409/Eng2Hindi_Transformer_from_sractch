{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from config import get_config, latest_weights_file_path\n",
    "from train import get_model, get_ds, run_validation\n",
    "config= get_config()\n",
    "# config['datasource']='M:\\Order to PC\\CAD_Reconstruction\\opus_books'\n",
    "\n",
    "model_filename = latest_weights_file_path(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aarif1430\\english-to-hindi_weights\\tmodel_27.pt\n"
     ]
    }
   ],
   "source": [
    "print(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since Aarif1430/english-to-hindi couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at C:\\Users\\ms526\\.cache\\huggingface\\datasets\\Aarif1430___english-to-hindi\\default\\0.0.0\\ecd7a3bf82a6c8c09551b39023d203551b61c1c3 (last modified on Sun Mar 30 19:45:26 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentence: 432\n",
      "Max length of target sentence: 435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "train_dataloader , val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
    "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Source: Just as it had once brought Banita face to face with a prime minister and then relegated her to angst-ridden anonymity , it brought her current plight to the notice of Bhakta Charan Das , a former Union minister and president of the Orissa Nava Nirman Manch .\n",
      "Expected: प्रधानमंत्री से रू-ब-रू होने और उसके बाद दुखभरी गुमनामी में खो जाने के बाद उसकी वर्तमान दशा की खबर पूर्व केंद्रीय मंत्री और ओड़ीसा नवनिर्माण मंच के अध्यक्ष भक्तचरण दास को लगी .\n",
      "Predicted: जिस तरह उसने एक बार प्रधानमंत्री के साथ प्रधानमंत्री का सामना किया और उसके बाद को देखते हुए उसने को प्रधानमंत्री कार्यालय में आमंत्रित किया . यह समिति दास ने निष्कर्ष पर ले जाया कि ओड़ीसा का वर्तमान सर्वोक्षण किया जाए .\n",
      "--------------------------------------------------------------------------------\n",
      "Source: Remember, the deck was stacked against you.\n",
      "Expected: याद कीजिये, संभावनाएं आपके खिलाफ थीं|\n",
      "Predicted: ज़रा देखिये , संभावनाएं आपके खिलाफ थीं |\n",
      "--------------------------------------------------------------------------------\n",
      "Source: Just a week ago when Sri Lankan President Chandrika Kumaratunga arrived at the Parliament complex in a sleek American Bell-412 helicopter to table her coalition Government 's constitutional reforms , it looked as if she was beginning to pull out of the political hole she had dug for herself .\n",
      "Expected: हता भर पहले श्रीलंका की राष्ट्रपति चंद्रिका कुमारतुंगा अपनी साज्ह सरकार के संवैधानिक सुधारों को पेश करने के लिए अमेरिकी बेल-412 हेलिकॉप्टर में बै कर संसद भवन फंचीं तो लगा कि वे उस राजनैतिक गड्ढें से निकलने लगी हैं जो उन्होंने खुद अपने लिए खोदा था .\n",
      "Predicted: भर पहले श्रीलंका राष्ट्रपति कुमारतुंगा अपनी साज्ह सरकार के संवैधानिक सुधारों को पेश करने के लिए अमेरिकी बेल - में बै कर संसद भवन तो लगा कि वे उस राजनैतिक से निकलने लगी हैं .\n",
      "--------------------------------------------------------------------------------\n",
      "Source: Chile's catching up!\n",
      "Expected: चिली आगे बढ रहा है।\n",
      "Predicted: चिली के साथ हो रहा है ।\n",
      "--------------------------------------------------------------------------------\n",
      "Source: and then only things that have started forming already\n",
      "Expected: उसके बाद केवल वही चीज़ें आकार लेती रहेंगी जिनका आकार लेना पहले ही शुरू हो चुका है\n",
      "Predicted: और तब ही चीज़े बनाना शुरू हो चुका है\n",
      "--------------------------------------------------------------------------------\n",
      "Source: In 1781 the right to appeal from the judgements of Sudder Dewani Adawlut of Bengal was also recognised , and Regulation XVI of 1797 limited this right in point of time to a period of six months from the date of judgement ,\n",
      "Expected: 1781 में बंगाल के मुख्य सिविल न्यायालय के निर्णयों की अपील करने के अधिकार को भी मान्यता प्रदान की गऋं और 1797 के विनियम 16 ने इस अधिकार को निर्णय की तारीख के छह महीने के अंदर प्रयोग किए जाने तक सीमित कर दिया गया .\n",
      "Predicted: में बंगाल के मुख्य न्यायालय के निर्णय के विरुद्ध अपील की जा सकती थी और के विनियम तथा विनियम Zके अनुसार , छह मास के निर्णयों की अपील सीमित अवधि तक सीमित सीमित थी .\n",
      "--------------------------------------------------------------------------------\n",
      "Source: I shudder at the thought at what they must have done to the entire security system of our country .\n",
      "Expected: मैं इस विचार से कांप उ ता ंं कि उन लगों ने हमारे देश की समूची सुरक्षा व्यवस्था को कितनी क्षति फंचाई होगी .\n",
      "Predicted: मैंने सोचा कि जिस हालत पर उन्होंने जो कुछ किया है उसे पूरा करने के लिए उन्होंने किया है , उसे पूरा सुरक्षा प्रणाली में मदद करना चाहिए .\n",
      "--------------------------------------------------------------------------------\n",
      "Source: and that the brain cells last 80 years or so.\n",
      "Expected: और दिमाग के कोषाणु ८० साल तक चलते हैं.\n",
      "Predicted: और दिमाग की कोशिकाएं ८० साल या उस से भी होती हैं ।\n",
      "--------------------------------------------------------------------------------\n",
      "Source: They were looking the next Karmapa,\n",
      "Expected: वे अगले करमापा की खोज कर रहे थे\n",
      "Predicted: वे अगले करमापा की खोज कर रहे थे\n",
      "--------------------------------------------------------------------------------\n",
      "Source: he had a son kmaal& a daughter kamaali\n",
      "Expected: जनश्रुति के अनुसार उन्हें एक पुत्र कमाल तथा पुत्री कमाली थी।\n",
      "Predicted: जनश्रुति के अनुसार उन्हें एक पुत्र कमाल तथा पुत्री कमाली थी ।\n"
     ]
    }
   ],
   "source": [
    "run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: print(msg), 0, None, num_examples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x EncoderBlock(\n",
       "        (self_attention_block): MultiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_o): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward_block): FeedForwardBlock(\n",
       "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (residual_connections): ModuleList(\n",
       "          (0-1): 2 x ResidualConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNormalization()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNormalization()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x DecoderBlock(\n",
       "        (self_attention_block): MultiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_o): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (cross_attention_block): MultiHeadAttentionBlock(\n",
       "          (w_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_k): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_v): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_o): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward_block): FeedForwardBlock(\n",
       "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (residual_connections): ModuleList(\n",
       "          (0-2): 3 x ResidualConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNormalization()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNormalization()\n",
       "  )\n",
       "  (src_embed): InputEmbeddings(\n",
       "    (embedding): Embedding(30000, 512)\n",
       "  )\n",
       "  (tgt_embed): InputEmbeddings(\n",
       "    (embedding): Embedding(30000, 512)\n",
       "  )\n",
       "  (src_pos): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (tgt_pos): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (projection_layer): ProjectionLayer(\n",
       "    (proj): Linear(in_features=512, out_features=30000, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 90213680\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
